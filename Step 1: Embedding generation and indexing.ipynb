{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d38a858-6a8c-4f31-8cf5-28daef888731",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The goal of the following code is to embed the descriptions of the tables based on schema that were created by prompting the MPT-7B Instruct model, generating their embeddings and storing in a vector database. Please note that for 10-20 tables, simple cosine similarity would be suffice. However, the vector database Chroma is employed here such that the solution can scale as more denormalized gold layer tables are added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9963eb5-1fb3-40da-b7c9-908ee8dad588",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting chromadb\n  Downloading chromadb-0.3.22-py3-none-any.whl (69 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 69.2/69.2 kB 2.1 MB/s eta 0:00:00\nCollecting duckdb>=0.7.1\n  Downloading duckdb-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.2/15.2 MB 41.2 MB/s eta 0:00:00\nCollecting numpy>=1.21.6\n  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.3/17.3 MB 78.0 MB/s eta 0:00:00\nRequirement already satisfied: pydantic>=1.9 in /databricks/python3/lib/python3.10/site-packages (from chromadb) (1.10.7)\nCollecting posthog>=2.4.0\n  Downloading posthog-3.0.1-py2.py3-none-any.whl (37 kB)\nCollecting clickhouse-connect>=0.5.7\n  Downloading clickhouse_connect-0.5.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 922.6/922.6 kB 73.4 MB/s eta 0:00:00\nCollecting sentence-transformers>=2.2.2\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.0/86.0 kB 19.3 MB/s eta 0:00:00\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nRequirement already satisfied: requests>=2.28 in /databricks/python3/lib/python3.10/site-packages (from chromadb) (2.28.1)\nRequirement already satisfied: pandas>=1.3 in /databricks/python3/lib/python3.10/site-packages (from chromadb) (1.4.4)\nCollecting typing-extensions>=4.5.0\n  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\nCollecting hnswlib>=0.7\n  Downloading hnswlib-0.7.0.tar.gz (33 kB)\n  Installing build dependencies: started\n  Installing build dependencies: finished with status 'done'\n  Getting requirements to build wheel: started\n  Getting requirements to build wheel: finished with status 'done'\n  Preparing metadata (pyproject.toml): started\n  Preparing metadata (pyproject.toml): finished with status 'done'\nCollecting uvicorn[standard]>=0.18.3\n  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 13.3 MB/s eta 0:00:00\nCollecting fastapi>=0.85.1\n  Downloading fastapi-0.95.1-py3-none-any.whl (56 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.0/57.0 kB 13.4 MB/s eta 0:00:00\nRequirement already satisfied: urllib3>=1.26 in /databricks/python3/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.11)\nCollecting zstandard\n  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.7/2.7 MB 110.6 MB/s eta 0:00:00\nCollecting lz4\n  Downloading lz4-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 92.9 MB/s eta 0:00:00\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.9.14)\nRequirement already satisfied: pytz in /databricks/python3/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.1)\nCollecting starlette<0.27.0,>=0.26.1\n  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.9/66.9 kB 16.6 MB/s eta 0:00:00\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.10/site-packages (from pandas>=1.3->chromadb) (2.8.2)\nCollecting backoff>=1.10.0\n  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\nCollecting monotonic>=1.5\n  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.28->chromadb) (2.0.4)\nRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb) (4.26.1)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb) (4.64.1)\nRequirement already satisfied: torch>=1.6.0 in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.13.1+cu117)\nRequirement already satisfied: torchvision in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb) (0.14.1+cu117)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.1.1)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.9.1)\nRequirement already satisfied: nltk in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb) (3.7)\nCollecting sentencepiece\n  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 101.9 MB/s eta 0:00:00\nRequirement already satisfied: huggingface-hub>=0.4.0 in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb) (0.13.3)\nRequirement already satisfied: click>=7.0 in /databricks/python3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.0.4)\nCollecting h11>=0.8\n  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 13.7 MB/s eta 0:00:00\nRequirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\nCollecting websockets>=10.4\n  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 129.9/129.9 kB 30.4 MB/s eta 0:00:00\nCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.1/4.1 MB 117.7 MB/s eta 0:00:00\nCollecting python-dotenv>=0.13\n  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\nCollecting httptools>=0.5.0\n  Downloading httptools-0.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (414 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 414.1/414.1 kB 58.1 MB/s eta 0:00:00\nCollecting watchfiles>=0.13\n  Downloading watchfiles-0.19.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 90.8 MB/s eta 0:00:00\nRequirement already satisfied: packaging>=20.9 in /databricks/python3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (21.3)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (3.6.0)\nCollecting anyio<5,>=3.4.0\n  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.6/80.6 kB 19.0 MB/s eta 0:00:00\nRequirement already satisfied: regex!=2019.12.17 in /databricks/python3/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (2022.7.9)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /databricks/python3/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (0.13.2)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.10/site-packages (from nltk->sentence-transformers>=2.2.2->chromadb) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb) (2.2.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /databricks/python3/lib/python3.10/site-packages (from torchvision->sentence-transformers>=2.2.2->chromadb) (9.2.0)\nCollecting sniffio>=1.1\n  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (3.0.9)\nBuilding wheels for collected packages: hnswlib, sentence-transformers\n  Building wheel for hnswlib (pyproject.toml): started\n  Building wheel for hnswlib (pyproject.toml): finished with status 'done'\n  Created wheel for hnswlib: filename=hnswlib-0.7.0-cp310-cp310-linux_x86_64.whl size=2155944 sha256=e0fca886eb5afd8bd0e65c42498eb45fb4efe74b48b48291f2e210344e1c5f97\n  Stored in directory: /root/.cache/pip/wheels/8a/ae/ec/235a682e0041fbaeee389843670581ec6c66872db856dfa9a4\n  Building wheel for sentence-transformers (setup.py): started\n  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125925 sha256=a7bc1dcd313c965697d950ee8bb2d41abb41a94849304b37dae982ee299c3ac9\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\nSuccessfully built hnswlib sentence-transformers\nInstalling collected packages: sentencepiece, monotonic, duckdb, zstandard, websockets, uvloop, typing-extensions, sniffio, python-dotenv, numpy, lz4, httptools, h11, backoff, uvicorn, posthog, hnswlib, clickhouse-connect, anyio, watchfiles, starlette, sentence-transformers, fastapi, chromadb\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.3.0\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-38353d97-23d7-4ddd-88bd-8f065fa12fb7\n    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.21.5\n    Not uninstalling numpy at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-38353d97-23d7-4ddd-88bd-8f065fa12fb7\n    Can't uninstall 'numpy'. No files were found to uninstall.\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npetastorm 0.12.1 requires pyspark>=2.1.0, which is not installed.\ndatabricks-feature-store 0.11.0 requires pyspark<4,>=3.1.2, which is not installed.\nydata-profiling 4.1.0 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\nnumba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.24.3 which is incompatible.\nmleap 0.20.0 requires scikit-learn<0.23.0,>=0.22.0, but you have scikit-learn 1.1.1 which is incompatible.\nSuccessfully installed anyio-3.6.2 backoff-2.2.1 chromadb-0.3.22 clickhouse-connect-0.5.24 duckdb-0.7.1 fastapi-0.95.1 h11-0.14.0 hnswlib-0.7.0 httptools-0.5.0 lz4-4.3.2 monotonic-1.6 numpy-1.24.3 posthog-3.0.1 python-dotenv-1.0.0 sentence-transformers-2.2.2 sentencepiece-0.1.99 sniffio-1.3.0 starlette-0.26.1 typing-extensions-4.5.0 uvicorn-0.22.0 uvloop-0.17.0 watchfiles-0.19.0 websockets-11.0.3 zstandard-0.21.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d875be89-1ffa-4309-af0d-13931f9ed88b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import time\n",
    "from chromadb.utils import embedding_functions\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "from sys import version_info\n",
    "import cloudpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24162436-8dd4-42ad-929d-1114990dbcb0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": null
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "USE CATALOG metsql;\n",
    "USE DATABASE metabase;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd1f00e5-85e2-462d-8f34-bf5837f7018a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>table_metadata</th><th>table_names</th><th>table_description</th></tr></thead><tbody><tr><td>schema: tbl[bank_churn] cols [RowNumber, CustomerId, Surname, CreditScore, Geography, Gender, Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary, Exited, Complain, Satisfaction Score, Card Type, Point Earned]</td><td>bank_churn</td><td>This table contains information about customers who have left their banking provider in the last 12 months (the churn column). The data includes demographic and behavioural characteristics as well as financial details for each customer.</td></tr><tr><td>schema: tbl[cars] cols [price, brand, model, year, title_status, mileage, color, vin, lot, state, country, condition]</td><td>cars</td><td>The cars table contains price,brand,model,year,title status,mileage and various other attributes for different car models</td></tr><tr><td>schema: tbl[commodity_prices] cols [date, oil_brent, oil_dubai, coffee_arabica, coffee_robustas, tea_columbo, tea_kolkata, tea_mombasa, sugar_eu, sugar_us, sugar_world]</td><td>commodity_prices</td><td>A table with commodity prices over time</td></tr><tr><td>schema: tbl[hmeq] cols [BAD, LOAN, MORTDUE, VALUE, REASON, JOB, YOJ, DEROG, DELINQ, CLAGE, NINQ, CLNO, DEBTINC]</td><td>hmeq</td><td>This table contains data on customers with loans and mortgages from HME Equity company in 2022. The columns are as follows BAD (Boolean), LOAN(String),MORTDUE(Integer),VALUE(Double),REASON(Text),JOB(Text),YOJ(Integer),DEROG(Boolean),DELINQ(Boolean),CLAGE(Integer),NINQ(Boolean),CLNO(Integer),DEBTINC(Double).</td></tr><tr><td>schema: tbl[mushrooms] cols [cap_shape, cap_surface, cap_color, bruises, odor, gill_attachment, gill_spacing, gill_size, gill_color, stalk_shape, stalk_root, stalk_surface_above_ring, stalk_surface_below_ring, stalk_color_above_ring, stalk_color_below_ring, veil_type, veil_color, ring_number, ring_type, spore_point_color, population, habitat, poisonous]</td><td>mushrooms</td><td>This dataset contains information about different types and varieties of mushrooms with their respective characteristics such as shape, color etc</td></tr><tr><td>schema: tbl[name_counts] cols [Name, Gender, Count, Probability]</td><td>name_counts</td><td>A table with names and their counts grouped by gender</td></tr><tr><td>schema: tbl[rent] cols [Posted On, BHK, Rent, Size, Floor, Area Type, Area Locality, City, Furnishing Status, Tenant Preferred, Bathroom, Point of Contact]</td><td>rent</td><td>A table with various attributes related to rental properties including their location and other information about them</td></tr><tr><td>schema: tbl[sales] cols [Invoice ID, Branch, City, Customer type, Gender, Product line, Unit price, Quantity, Tax 5%, Total, Date, Time, Payment, cogs, gross margin percentage, gross income, Rating]</td><td>sales</td><td>Sales data with multiple dimensions including branch location and customer types by product lines</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "schema: tbl[bank_churn] cols [RowNumber, CustomerId, Surname, CreditScore, Geography, Gender, Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary, Exited, Complain, Satisfaction Score, Card Type, Point Earned]",
         "bank_churn",
         "This table contains information about customers who have left their banking provider in the last 12 months (the churn column). The data includes demographic and behavioural characteristics as well as financial details for each customer."
        ],
        [
         "schema: tbl[cars] cols [price, brand, model, year, title_status, mileage, color, vin, lot, state, country, condition]",
         "cars",
         "The cars table contains price,brand,model,year,title status,mileage and various other attributes for different car models"
        ],
        [
         "schema: tbl[commodity_prices] cols [date, oil_brent, oil_dubai, coffee_arabica, coffee_robustas, tea_columbo, tea_kolkata, tea_mombasa, sugar_eu, sugar_us, sugar_world]",
         "commodity_prices",
         "A table with commodity prices over time"
        ],
        [
         "schema: tbl[hmeq] cols [BAD, LOAN, MORTDUE, VALUE, REASON, JOB, YOJ, DEROG, DELINQ, CLAGE, NINQ, CLNO, DEBTINC]",
         "hmeq",
         "This table contains data on customers with loans and mortgages from HME Equity company in 2022. The columns are as follows BAD (Boolean), LOAN(String),MORTDUE(Integer),VALUE(Double),REASON(Text),JOB(Text),YOJ(Integer),DEROG(Boolean),DELINQ(Boolean),CLAGE(Integer),NINQ(Boolean),CLNO(Integer),DEBTINC(Double)."
        ],
        [
         "schema: tbl[mushrooms] cols [cap_shape, cap_surface, cap_color, bruises, odor, gill_attachment, gill_spacing, gill_size, gill_color, stalk_shape, stalk_root, stalk_surface_above_ring, stalk_surface_below_ring, stalk_color_above_ring, stalk_color_below_ring, veil_type, veil_color, ring_number, ring_type, spore_point_color, population, habitat, poisonous]",
         "mushrooms",
         "This dataset contains information about different types and varieties of mushrooms with their respective characteristics such as shape, color etc"
        ],
        [
         "schema: tbl[name_counts] cols [Name, Gender, Count, Probability]",
         "name_counts",
         "A table with names and their counts grouped by gender"
        ],
        [
         "schema: tbl[rent] cols [Posted On, BHK, Rent, Size, Floor, Area Type, Area Locality, City, Furnishing Status, Tenant Preferred, Bathroom, Point of Contact]",
         "rent",
         "A table with various attributes related to rental properties including their location and other information about them"
        ],
        [
         "schema: tbl[sales] cols [Invoice ID, Branch, City, Customer type, Gender, Product line, Unit price, Quantity, Tax 5%, Total, Date, Time, Payment, cogs, gross margin percentage, gross income, Rating]",
         "sales",
         "Sales data with multiple dimensions including branch location and customer types by product lines"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "table_metadata",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "table_names",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "table_description",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadf = spark.sql(\"SELECT * FROM metadata_table\")\n",
    "display(metadf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1ed6b8c-b727-4da5-a52b-fadd25f81dc9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "persist_directory = \"/dbfs/FileStore/shared_uploads/avinash.sooriyarachchi@databricks.com/metsqlchroma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34684425-1d23-449d-8527-192915ee8688",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: /dbfs/FileStore/shared_uploads/avinash.sooriyarachchi@databricks.com/metsqlchroma\n"
     ]
    }
   ],
   "source": [
    "# setup Chroma in-memory, for easy prototyping. Can add persistence easily!\n",
    "client = chromadb.Client(\n",
    "      Settings(\n",
    "        persist_directory=persist_directory,\n",
    "        chroma_db_impl=\"duckdb+parquet\",\n",
    "        \n",
    "    )\n",
    ")\n",
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
    "# Create collection. get_collection, get_or_create_collection, delete_collection also available!\n",
    "collection = client.create_collection(name=\"metadata_vdb\", embedding_function=sentence_transformer_ef) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a00c0cf2-186c-401d-a5f4-36f1b10275b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "metadf_pd = metadf.toPandas()\n",
    "table_descriptions = metadf_pd.table_description.to_list()\n",
    "table_names = metadf_pd.table_names.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "810a172f-867f-456d-88ea-6f5085172b9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_metadata = metadf_pd.table_metadata.apply(lambda x: {\"table_metadata\": x}).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52e5931f-7761-428b-a2d4-aa539a6b7c92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('This table contains information about customers who have left their banking provider in the last 12 months (the churn column). The data includes demographic and behavioural characteristics as well as financial details for each customer.',\n",
       " 'schema: tbl[bank_churn] cols [RowNumber, CustomerId, Surname, CreditScore, Geography, Gender, Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary, Exited, Complain, Satisfaction Score, Card Type, Point Earned]')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_descriptions[0], table_metadata[0][\"table_metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd665752-d2d4-4659-b124-7941cc4b4664",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "collection.add(\n",
    "  documents=table_descriptions, # we handle tokenization, embedding, and indexing automatically. You can skip that and add your own embeddings as well\n",
    "  metadatas=table_metadata, # filter on these!\n",
    "  ids=table_names, # unique for each doc \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfd01663-44f2-4e0b-8a99-ec8959efb5eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75719059-bd14-4ff8-94b9-031399e65505",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = collection.query(\n",
    "    query_texts=[\"How many vehicles were sold in 2008?\"],\n",
    "    n_results=1,\n",
    "    # where={\"metadata_field\": \"is_equal_to_this\"}, # optional filter\n",
    "    # where_document={\"$contains\":\"search_string\"}  # optional filter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f69c2cb-0c50-494b-9e96-da25723aa218",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'ids': [['cars']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['The cars table contains price,brand,model,year,title status,mileage and various other attributes for different car models']],\n",
       " 'metadatas': [[{'table_metadata': 'schema: tbl[cars] cols [price, brand, model, year, title_status, mileage, color, vin, lot, state, country, condition]'}]],\n",
       " 'distances': [[1.0797241926193237]]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b572f34-4af5-44aa-a0cd-d3e4df4cc43b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Testing:\n",
    "### Now load the vector database from disk and query again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1ed7f0f-e624-4f23-945a-be63a8f1e4a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
    "# Create a new client with the same settings\n",
    "client = chromadb.Client(\n",
    "    Settings(\n",
    "        persist_directory=persist_directory,\n",
    "        chroma_db_impl=\"duckdb+parquet\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Load the collection\n",
    "collection = client.get_collection(name=\"metadata_vdb\", embedding_function=sentence_transformer_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c852d29-d256-4a88-9ca8-acc82248b704",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = collection.query(\n",
    "    query_texts=[\"How many people named Alex are there in the US?\"],\n",
    "    n_results=1,\n",
    "    # where={\"metadata_field\": \"is_equal_to_this\"}, # optional filter\n",
    "    # where_document={\"$contains\":\"search_string\"}  # optional filter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "343bf9e2-c3ea-4055-854b-12c182215f90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'ids': [['name_counts']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['A table with names and their counts grouped by gender']],\n",
       " 'metadatas': [[{'table_metadata': 'schema: tbl[name_counts] cols [Name, Gender, Count, Probability]'}]],\n",
       " 'distances': [[1.3860574960708618]]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75afb279-32c1-4336-9bed-65bacfaa9d4b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'schema: tbl[name_counts] cols [Name, Gender, Count, Probability]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['metadatas'][0][0]['table_metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b513c2a-738b-46ca-98b7-4cc464fbe196",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'name_counts'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['ids'][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8ef51d7-e9a8-44d1-951d-f2eb59b42e89",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Register with MLFlow and Deploy to Serving\n",
    "Define a custom model pyfunc class to wrap the vector database and deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b7b743b-418e-4832-b6d3-fd3fb59812bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "class RelevantTableFinder(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "  def load_context(self, context):\n",
    "    import chromadb\n",
    "    from chromadb.config import Settings\n",
    "    from chromadb.utils import embedding_functions\n",
    "    self.sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
    "    # Create a new client with the same settings\n",
    "    self.client = chromadb.Client(\n",
    "        Settings(\n",
    "            persist_directory=context.artifacts[\"persist_directory\"],\n",
    "            chroma_db_impl=\"duckdb+parquet\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Load the collection\n",
    "    self.collection = self.client.get_collection(name=\"metadata_vdb\", embedding_function=self.sentence_transformer_ef)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def predict(self, context, model_input):\n",
    "    import json\n",
    "    question = model_input.iloc[:,0].to_list() # get the first column\n",
    "    results = self.collection.query(\n",
    "    query_texts=question,\n",
    "    n_results=1,\n",
    "    )\n",
    "    # The vector search is over the similar stack overflow questions. What needs to be concatenated are responses to the top 2 queries stored as metadata\n",
    "    responses = {\"table\": results['ids'][0][0], 'description': results['documents'][0][0], 'schema':results['metadatas'][0][0]['table_metadata']}\n",
    "    result = {'Response': responses}\n",
    "    return json.dumps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f53efab7-d46f-473d-9d49-316c1a3da21a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Sample Question\n",
    "payload_pd = pd.DataFrame([[\"How many cars sold in 2018?\"]],columns=['text'])\n",
    "input_example = payload_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9abe1f1e-8350-4197-b983-e741496e02f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "PYTHON_VERSION = \"{major}.{minor}.{micro}\".format(major=version_info.major,\n",
    "                                                  minor=version_info.minor,\n",
    "                                                  micro=version_info.micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac724706-3fbe-4bf6-887c-6b5814462543",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "conda_env = {\n",
    "    'channels': ['defaults'],\n",
    "    'dependencies': [\n",
    "      'python={}'.format(PYTHON_VERSION),\n",
    "      'pip',\n",
    "      {\n",
    "        'pip': [\n",
    "          'mlflow',\n",
    "          'transformers',\n",
    "          'pandas',\n",
    "          'chromadb',\n",
    "          'cloudpickle=={}'.format(cloudpickle.__version__),\n",
    "          'torch'],\n",
    "      },\n",
    "    ],\n",
    "    'name': 'code_env'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e66ad75-6c77-42ef-a84c-9280bf23d7d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow_pyfunc_model_path = \"tablemetadata_vectordb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "229b2644-f9ae-4f4a-a936-f3fa75e1c2d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "artifacts = {\n",
    "   \"persist_directory\": persist_directory\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c433be8-0dc4-4ed1-add8-5eb25ac3f241",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x7f011ad66620>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.pyfunc.log_model(artifact_path=mlflow_pyfunc_model_path, python_model=RelevantTableFinder(),artifacts=artifacts, conda_env=conda_env, input_example = input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0fe269a2-7de1-4c05-a03e-98623857644a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loraadapter_location = \"/dbfs/FileStore/shared_uploads/avinash.sooriyarachchi@databricks.com/text_to_sql/flt5txt2sql\""
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2272171370901828,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Step 1: Embedding generation and indexing",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
