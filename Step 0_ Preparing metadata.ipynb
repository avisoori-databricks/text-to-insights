{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e5a3253-3f14-49d5-a4b1-d7ae9c7f46db",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Download mpt-7B model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5dd6c7b-a941-46ef-bab9-badbd0e7c995",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We install the necessary packages to be able to perform inference with MPT-7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "981da230-bde2-4096-bc98-d489dcce7712",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/libcusparse-dev-11-7_11.7.3.50-1_amd64.deb && \\\n",
    "  dpkg -i libcusparse-dev-11-7_11.7.3.50-1_amd64.deb && \\\n",
    "  wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/libcublas-dev-11-7_11.10.1.25-1_amd64.deb && \\\n",
    "  dpkg -i libcublas-dev-11-7_11.10.1.25-1_amd64.deb && \\\n",
    "  wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/libcusolver-dev-11-7_11.4.0.1-1_amd64.deb && \\\n",
    "  dpkg -i libcusolver-dev-11-7_11.4.0.1-1_amd64.deb\n",
    "%pip install ninja\n",
    "%pip install langchain chromadb einops flash-attn==v1.0.3.post0 triton==2.0.0.dev20221202"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84bf510a-83e7-48c3-8176-0d68a0b0cbcd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81bd3d5f-db25-4989-a461-95e7223de834",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9dd4f734-8936-4433-bd00-2d825dceaea4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Load the MPT-7B Instruct model from the Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3952250-f68c-4f44-98fc-592a6f5a8365",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "  'mosaicml/mpt-7b-instruct',\n",
    "  trust_remote_code=True\n",
    ")\n",
    "config.attn_config['attn_impl'] = 'triton'\n",
    "#config.update({\"max_seq_len\": 4096})\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  'mosaicml/mpt-7b-instruct',\n",
    "  config=config,\n",
    "  torch_dtype=torch.bfloat16,\n",
    "  trust_remote_code=True\n",
    ").to(device=\"cuda:0\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61072571-b55d-4a58-a28e-7bd9075c0d8b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc7b6bc4-6964-46c9-be9e-21eecce707ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Tests to see the text input is valid \n",
    "import pandas as pd\n",
    "\n",
    "payload_pd = pd.DataFrame([[\"Generate description of following schema: tbl[cars] cols [price, brand, model, year, title_status, mileage, color, vin, lot, state, country, condition]\"]],columns=['text'])\n",
    "payload_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63e2ae4e-b9b8-4b20-b840-fc1fad7b13d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "instruction = payload_pd.iloc[:,0].to_list() # get the first column\n",
    "instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3b2fad5-833e-4442-9ae7-8dc40aba4c38",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Create the different compoenents necessary to perform inference with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aedc4996-bdf4-455b-9331-6baa6af75703",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "INSTRUCTION_KEY = \"### Instruction:\"\n",
    "RESPONSE_KEY = \"### Response:\"\n",
    "END_KEY = \"### End\"\n",
    "INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
    "PROMPT_FOR_GENERATION_FORMAT = \"\"\"{intro}\n",
    "{instruction_key}\n",
    "{instruction}\n",
    "{response_key}\n",
    "\"\"\".format(\n",
    "    intro=INTRO_BLURB,\n",
    "    instruction_key=INSTRUCTION_KEY,\n",
    "    instruction=\"{instruction}\",\n",
    "    response_key=RESPONSE_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e46c3852-f65c-49f3-82da-c61554984f9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "s = PROMPT_FOR_GENERATION_FORMAT.format(instruction=instruction[0])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "624bd011-8a7e-41b2-bac4-f3c75add3e90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "generate_kwargs = {\n",
    "            \"temperature\": 0.5,\n",
    "            \"top_p\": 92,\n",
    "            \"top_k\": 0,\n",
    "            \"max_new_tokens\": 512,\n",
    "            \"use_cache\": True,\n",
    "            \"do_sample\": True,\n",
    "            \"eos_token_id\": tokenizer.eos_token_id,\n",
    "            \"pad_token_id\": tokenizer.pad_token_id,\n",
    "            \"repetition_penalty\": 1.1,  # 1.0 means no penalty, > 1.0 means penalty, 1.2 from CTRL paper\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b33efd20-498d-413b-af55-7fa7eb37cf38",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_ids = tokenizer(s, return_tensors=\"pt\").input_ids\n",
    "input_ids = input_ids.to(model.device)\n",
    "gkw = {**generate_kwargs}\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(input_ids, **gkw)\n",
    "# Slice the output_ids tensor to get only new tokens\n",
    "new_tokens = output_ids[0, len(input_ids[0]) :]\n",
    "output_text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89671b39-7c9e-4dac-8ec7-0685aeadfde0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Wrap the above logic into a function \n",
    "#variable 'instruction' is what is asked\n",
    "def generate_response(tokenizer, model, instruction):\n",
    "  INSTRUCTION_KEY = \"### Instruction:\"\n",
    "  RESPONSE_KEY = \"### Response:\"\n",
    "  END_KEY = \"### End\"\n",
    "  INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
    "  PROMPT_FOR_GENERATION_FORMAT = \"\"\"{intro}\n",
    "  {instruction_key}\n",
    "  {instruction}\n",
    "  {response_key}\n",
    "  \"\"\".format(\n",
    "      intro=INTRO_BLURB,\n",
    "      instruction_key=INSTRUCTION_KEY,\n",
    "      instruction=\"{instruction}\",\n",
    "      response_key=RESPONSE_KEY,\n",
    "  )\n",
    "  s = PROMPT_FOR_GENERATION_FORMAT.format(instruction=instruction)\n",
    "  generate_kwargs = {\n",
    "            \"temperature\": 0.5,\n",
    "            \"top_p\": 92,\n",
    "            \"top_k\": 0,\n",
    "            \"max_new_tokens\": 512,\n",
    "            \"use_cache\": True,\n",
    "            \"do_sample\": True,\n",
    "            \"eos_token_id\": tokenizer.eos_token_id,\n",
    "            \"pad_token_id\": tokenizer.pad_token_id,\n",
    "            \"repetition_penalty\": 1.1,  # 1.0 means no penalty, > 1.0 means penalty, 1.2 from CTRL paper\n",
    "        }\n",
    "  input_ids = tokenizer(s, return_tensors=\"pt\").input_ids\n",
    "  input_ids = input_ids.to(model.device)\n",
    "  gkw = {**generate_kwargs}\n",
    "  with torch.no_grad():\n",
    "      output_ids = model.generate(input_ids, **gkw)\n",
    "  # Slice the output_ids tensor to get only new tokens\n",
    "  new_tokens = output_ids[0, len(input_ids[0]) :]\n",
    "  output_text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "  return output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2565599-a4c2-426e-b711-af67e5e0470c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Testing the inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7b85959-38b0-48d0-9c8b-e945b39dde67",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "generate_response(tokenizer, model, \"What is SQL. Describe briefly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ba9d542-e3e0-43ce-92da-e78e9dc98f6f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Creating Catalog, Database and example 'gold' tables\n",
    "For the purpose of this demo, I will create a completely new gold layer with denormalized tables that would be representative of a toy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c81bcc1-39c5-4d02-9724-678c672b5bfc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE CATALOG IF NOT EXISTS METSQL;\n",
    "USE CATALOG metsql;\n",
    "CREATE DATABASE IF NOT EXISTS GOLDDB;\n",
    "USE GOLDDB;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1126f84a-c93c-42db-a7b7-ddd1b307f465",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Create dataframe with metadata, table names and table description generated by MPT-7B based on schema. This description will be used to match a given natural language question by indexing it using a vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c885000f-01db-4df0-8351-09e11f477102",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List tables in the current database\n",
    "tables = spark.sql(\"SHOW TABLES\")\n",
    "\n",
    "# Initialize a list to store the table metadata\n",
    "table_metadata = []\n",
    "table_names = []\n",
    "table_description = []\n",
    "\n",
    "# Iterate over the tables and retrieve the column names\n",
    "for row in tables.collect():\n",
    "    table_name = row.tableName\n",
    "    columns = spark.sql(f\"DESCRIBE {table_name}\")\n",
    "    column_names = [column.col_name for column in columns.collect()]\n",
    "    metadata_str = f\"schema: tbl[{table_name}] cols [{', '.join(column_names)}]\"\n",
    "    table_metadata.append(metadata_str)\n",
    "    table_names.append(table_name)\n",
    "    description = generate_response(tokenizer, model, \"Generate a brief description of the following \"+metadata_str)\n",
    "    table_description.append(description)\n",
    "\n",
    "# Print the table metadata\n",
    "for i in range(len(table_metadata)):\n",
    "    print(table_metadata[i]), print(table_names[i]), print(table_description[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1524bc2-b17a-4c1e-a0eb-b0aadc9119a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create the DataFrame\n",
    "df = pd.DataFrame({'table_metadata': table_metadata, 'table_names': table_names, 'table_description': table_description})\n",
    "\n",
    "# Print the DataFrame\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6c8e875-7a53-4f83-b2b3-183be3983198",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(df).write.saveAsTable('table_metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b0f70e5-910d-49e9-8fd4-c98aefc89615",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "name_schema = [[table_names[i], table_metadata[i]] for i in range(len(table_names))]\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame({'table_metadata': name_schema, 'table_names': table_names, 'table_description': table_description})\n",
    "\n",
    "# Print the DataFrame\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "415f795a-485c-4bf3-98f7-344cdfaf834e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Now save this in a table in new database Metabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1cb89d1-1003-41c1-b2b0-82dfaf930912",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE DATABASE IF NOT EXISTS METABASE;\n",
    "USE METABASE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37c5ec0c-b5e9-4ab1-b276-d62171b002ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(df).write.saveAsTable('metadata')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2272171370901814,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Step 0: Preparing metadata",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
